{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\bhavi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.28.1)\n",
      "Requirement already satisfied: requests in c:\\users\\bhavi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.29.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bhavi\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\bhavi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\bhavi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\bhavi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2023.3.23)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\bhavi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\bhavi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\bhavi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\bhavi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\bhavi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\bhavi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\bhavi\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bhavi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bhavi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bhavi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\bhavi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (1.26.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\bhavi\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\bhavi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bhavi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\bhavi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\bhavi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\bhavi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\bhavi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bhavi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\bhavi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\bhavi\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers\n",
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bhavi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-Trained BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "with open('model.pkl', 'wb') as handle:\n",
    "    pkl.dump(model, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_for_bert = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "with open('tokenizer.pkl', 'wb') as handle:\n",
    "    pkl.dump(tokenizer_for_bert, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2054, 4302, 9418, 102, 4302, 10693, 1998, 1996, 9667, 1005, 1055, 2962, 1010, 4302, 3268, 1999, 1037, 25337, 2104, 1996, 5108, 1999, 1996, 2160, 1997, 1996, 4241, 2869, 3051, 2015, 1010, 2010, 5916, 1010, 4470, 1998, 5542, 1010, 12648, 1012, 1996, 4241, 2869, 3051, 2015, 5136, 3209, 6669, 3671, 1010, 2021, 2012, 1996, 2287, 1997, 2340, 1010, 4302, 9418, 2008, 2002, 2003, 1037, 10276, 1012, 2002, 6010, 1037, 2431, 1011, 5016, 2315, 5292, 16523, 3593, 2040, 18675, 2032, 2000, 5463, 1996, 27589, 18367, 2015, 2082, 1997, 21599, 1998, 10276, 2854, 1012, 4302, 10229, 2008, 2004, 1037, 3336, 1010, 2010, 3008, 2020, 7129, 2011, 1996, 2601, 10276, 2935, 5285, 3207, 5302, 5339, 1012, 2043, 5285, 3207, 5302, 5339, 4692, 2000, 3102, 4302, 1010, 2010, 8364, 27755, 2098, 1998, 4302, 5175, 2007, 1037, 7407, 1011, 5044, 11228, 2006, 2010, 6130, 1012, 102]\n",
      "[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "['[CLS]', 'what', 'harry', 'discovers', '[SEP]', 'harry', 'potter', 'and', 'the', 'philosopher', \"'\", 's', 'stone', ',', 'harry', 'lives', 'in', 'a', 'cupboard', 'under', 'the', 'stairs', 'in', 'the', 'house', 'of', 'the', 'du', '##rs', '##ley', '##s', ',', 'his', 'aunt', ',', 'uncle', 'and', 'cousin', ',', 'dudley', '.', 'the', 'du', '##rs', '##ley', '##s', 'consider', 'themselves', 'perfectly', 'normal', ',', 'but', 'at', 'the', 'age', 'of', '11', ',', 'harry', 'discovers', 'that', 'he', 'is', 'a', 'wizard', '.', 'he', 'meets', 'a', 'half', '-', 'giant', 'named', 'ha', '##gr', '##id', 'who', 'invites', 'him', 'to', 'attend', 'the', 'hog', '##wart', '##s', 'school', 'of', 'witchcraft', 'and', 'wizard', '##ry', '.', 'harry', 'learns', 'that', 'as', 'a', 'baby', ',', 'his', 'parents', 'were', 'murdered', 'by', 'the', 'dark', 'wizard', 'lord', 'vol', '##de', '##mo', '##rt', '.', 'when', 'vol', '##de', '##mo', '##rt', 'attempted', 'to', 'kill', 'harry', ',', 'his', 'curse', 'rebound', '##ed', 'and', 'harry', 'survived', 'with', 'a', 'lightning', '-', 'shaped', 'scar', 'on', 'his', 'forehead', '.', '[SEP]']\n",
      "\n",
      "\n",
      "Torch Tensor Score of Start and End Tokens:\n",
      " tensor([[-5.2710, -6.2478, -6.9620, -8.8190, -5.2710,  1.2726, -4.2517, -4.1712,\n",
      "         -1.6694, -3.6989, -6.3545, -6.1063, -5.0507, -6.6658, -1.2385, -4.5760,\n",
      "         -6.2778, -5.0741, -4.9394, -6.0843, -7.9871, -6.6390, -7.0918, -6.1422,\n",
      "         -5.0692, -7.5268, -4.0576, -4.0900, -7.0156, -7.1728, -6.7855, -7.4929,\n",
      "         -3.8439, -5.5434, -8.4648, -6.7923, -8.0747, -5.5572, -8.1581, -4.9704,\n",
      "         -5.2711,  0.2368, -2.5031, -5.3747, -5.3659, -5.0212, -3.5281, -3.8299,\n",
      "         -3.0623, -3.5083, -5.4627,  0.5345,  3.4342,  0.6031, -0.0252, -3.1545,\n",
      "          0.2530, -1.7521,  4.6136,  1.5193,  3.6614,  4.1425, -0.5695,  0.7505,\n",
      "         -1.5349, -4.2509,  1.2698, -3.4325, -3.7189, -4.4959, -7.4131, -5.6022,\n",
      "         -6.5232, -3.0216, -6.3635, -6.0940, -6.4302, -3.8842, -4.9163, -5.3275,\n",
      "         -4.0435, -4.8735, -2.0895, -6.2211, -6.9127, -5.3288, -7.2282, -4.9377,\n",
      "         -6.8981, -5.6923, -6.1791, -4.7716,  2.3061, -2.7448, -0.9332, -0.5056,\n",
      "         -3.3777, -3.8624, -5.8127,  0.5892, -3.0109, -5.1455, -3.3621, -5.2245,\n",
      "         -3.3267, -3.2573, -3.9191, -1.8843, -3.3098, -6.1053, -6.6842, -5.2115,\n",
      "         -5.3360, -2.8519, -3.2916, -6.8800, -7.2192, -6.3630, -5.4322, -6.9802,\n",
      "         -5.5974, -4.6027, -7.5123, -4.2534, -3.8912, -5.8940, -6.6086, -7.1741,\n",
      "         -2.3964, -4.8980, -6.1936, -3.9714, -3.5633, -7.3838, -6.3776, -4.3666,\n",
      "         -7.8229, -7.3255, -5.5716, -6.9338, -5.2710]],\n",
      "       grad_fn=<CloneBackward0>) \n",
      " tensor([[-1.2794, -7.0530, -6.6568, -7.3539, -1.2794, -4.8598, -2.4010, -5.1207,\n",
      "         -5.5362, -5.6368, -7.1801, -5.5826, -0.2266, -2.9155, -4.4258, -5.1806,\n",
      "         -6.8929, -6.7195, -3.6471, -6.6813, -6.8847, -1.7785, -6.8396, -7.2869,\n",
      "         -3.6575, -7.1784, -7.2848, -6.1218, -5.8789, -4.6604, -0.6837, -5.0936,\n",
      "         -7.1091, -5.3497, -6.0928, -4.9266, -7.1511, -4.1658, -5.5683, -2.8782,\n",
      "         -1.2799, -5.4469, -5.5166, -5.3031, -4.4397, -2.0103, -5.5055, -4.8380,\n",
      "         -5.7660, -0.8265, -2.0716, -4.9893, -4.3827, -5.5413, -4.6412, -5.6230,\n",
      "         -0.1872, -2.5617, -2.4755, -2.3655, -4.3510, -4.1039, -4.4209, -4.1683,\n",
      "          4.6203,  4.1043, -3.5686, -4.4981, -6.5221, -6.6320, -6.9816, -1.1587,\n",
      "         -4.5146, -5.3113, -4.6049,  0.5567, -4.6438, -5.9211, -3.7476, -6.3211,\n",
      "         -5.0147, -7.1685, -5.9741, -5.6077, -4.0148, -3.8136, -6.7449, -4.2796,\n",
      "         -6.3568, -5.2876,  0.7856,  1.6545, -3.5494, -2.3369, -4.6813, -6.4249,\n",
      "         -6.9973, -2.2307, -4.4165, -6.1131, -3.7025, -5.0879, -1.7520, -4.9584,\n",
      "         -6.9411, -5.7555, -1.9674, -5.2641, -5.1652, -5.6736, -5.1224,  1.6768,\n",
      "          0.9925, -6.9107, -6.8201, -7.1289, -6.8379, -3.9640, -5.5219, -6.5127,\n",
      "         -5.5905, -1.7716, -5.2116, -7.3481, -4.0796, -5.3884, -2.6023, -6.5243,\n",
      "         -6.4927, -3.8386, -6.9883, -7.3596, -6.2282, -7.4212, -6.2445, -2.7705,\n",
      "         -7.4555, -6.6610, -0.3480,  0.3929, -1.2795]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "\n",
      "\n",
      "Converted Score of Tensor into Numpy Array:\n",
      " [-5.2710032  -6.247759   -6.9619703  -8.819006   -5.2709913   1.2725631\n",
      " -4.251728   -4.171195   -1.669392   -3.698874   -6.354514   -6.106278\n",
      " -5.050726   -6.6658106  -1.238513   -4.5760107  -6.277846   -5.0741324\n",
      " -4.9394493  -6.0843463  -7.987052   -6.638973   -7.091812   -6.1422462\n",
      " -5.069206   -7.5267906  -4.0575514  -4.0900393  -7.0155544  -7.1727877\n",
      " -6.785502   -7.492854   -3.8439212  -5.5433817  -8.464777   -6.792289\n",
      " -8.0746975  -5.5571513  -8.158083   -4.9703865  -5.271114    0.23682341\n",
      " -2.5030994  -5.374711   -5.365856   -5.0211935  -3.5281162  -3.8299084\n",
      " -3.062307   -3.5082674  -5.46269     0.5345488   3.434228    0.60313284\n",
      " -0.0251922  -3.1544633   0.25297475 -1.7521187   4.6135635   1.5193183\n",
      "  3.661406    4.1424665  -0.5695435   0.7504952  -1.534925   -4.2509108\n",
      "  1.2698134  -3.4324956  -3.7188568  -4.4958515  -7.41311    -5.602191\n",
      " -6.5232205  -3.0215628  -6.3635225  -6.094043   -6.4301896  -3.884232\n",
      " -4.9163165  -5.3275375  -4.043501   -4.8734674  -2.0895493  -6.221076\n",
      " -6.912663   -5.328815   -7.228158   -4.9377418  -6.8980737  -5.692296\n",
      " -6.1790543  -4.7715826   2.3061106  -2.7447925  -0.93323517 -0.5056134\n",
      " -3.3777385  -3.8623538  -5.8127255   0.5891564  -3.010915   -5.1455307\n",
      " -3.3621387  -5.2245116  -3.326727   -3.2573025  -3.919129   -1.8843241\n",
      " -3.3097935  -6.10528    -6.684204   -5.2115164  -5.3360415  -2.8518987\n",
      " -3.291586   -6.8800187  -7.2192287  -6.363      -5.4321976  -6.9802256\n",
      " -5.5974474  -4.6026793  -7.5122724  -4.253384   -3.891158   -5.89402\n",
      " -6.608592   -7.174055   -2.3963912  -4.8979607  -6.193617   -3.9713652\n",
      " -3.563315   -7.383791   -6.3776197  -4.366626   -7.8228893  -7.3255157\n",
      " -5.5716     -6.933838   -5.2709856 ] \n",
      " [-1.2793988  -7.0529914  -6.656843   -7.353917   -1.279357   -4.8598113\n",
      " -2.4010167  -5.1207485  -5.53624    -5.636832   -7.180069   -5.5826445\n",
      " -0.22655208 -2.9155028  -4.425774   -5.1805983  -6.8929443  -6.7194767\n",
      " -3.6471028  -6.6812525  -6.884676   -1.7785201  -6.8396034  -7.2869244\n",
      " -3.6575184  -7.178375   -7.2848263  -6.121764   -5.8789406  -4.66038\n",
      " -0.68369675 -5.093581   -7.1090946  -5.349698   -6.092781   -4.926619\n",
      " -7.151102   -4.1657686  -5.5682793  -2.8781936  -1.279937   -5.446896\n",
      " -5.5166416  -5.3030834  -4.439699   -2.010252   -5.5054812  -4.838\n",
      " -5.7659626  -0.82652265 -2.0715876  -4.989334   -4.382721   -5.5413384\n",
      " -4.6411786  -5.6230254  -0.1872127  -2.5617056  -2.475534   -2.3655193\n",
      " -4.3509836  -4.103938   -4.420899   -4.1682816   4.6203446   4.1043053\n",
      " -3.5686212  -4.498051   -6.522116   -6.6320276  -6.981585   -1.1587121\n",
      " -4.5146356  -5.311294   -4.604891    0.5566634  -4.6437674  -5.9210567\n",
      " -3.7476127  -6.3210754  -5.0147343  -7.1685004  -5.974133   -5.6077104\n",
      " -4.014846   -3.8135724  -6.744871   -4.279595   -6.3567777  -5.2876434\n",
      "  0.785644    1.6544528  -3.5493731  -2.336948   -4.6812773  -6.424898\n",
      " -6.997346   -2.2306728  -4.416543   -6.113071   -3.702453   -5.087921\n",
      " -1.7520442  -4.9584384  -6.9411316  -5.755543   -1.9673922  -5.2641335\n",
      " -5.1651835  -5.6736374  -5.1223736   1.67682     0.99250245 -6.9107275\n",
      " -6.82014    -7.128851   -6.8378773  -3.9640312  -5.5219088  -6.5126834\n",
      " -5.590481   -1.7715659  -5.2115903  -7.3481045  -4.079635   -5.38844\n",
      " -2.6023288  -6.524288   -6.49269    -3.83856    -6.9882936  -7.3595533\n",
      " -6.228177   -7.4212255  -6.2445254  -2.7704601  -7.455525   -6.660986\n",
      " -0.34800577  0.3929165  -1.2794507 ]\n",
      "\n",
      "\n",
      "Highest Score that matches with index of answer:\n",
      " 58 \n",
      " 64\n",
      "\n",
      "\n",
      "Maximum Score of start and end of the answer:\n",
      " 4.61 \n",
      " 4.62\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(58, 64, 4.61, 4.62, 'harry discovers that he is a wizard')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bert_question_answer(question, passage, max_len=500):\n",
    "\n",
    "  \"\"\" \n",
    "  question : What harry discovers\n",
    "  passage : Harry Potter and the Philosopher's Stone, Harry lives in a cupboard under the stairs in the\n",
    "    house of the Dursleys, his aunt, uncle and cousin, Dudley. The Dursleys consider themselves\n",
    "    perfectly normal, but at the age of 11, Harry discovers that he is a wizard. He meets a half-giant \n",
    "    named Hagrid who invites him to attend the Hogwarts School of Witchcraft and Wizardry. \n",
    "    Harry learns that as a baby, his parents were murdered by the dark wizard Lord Voldemort. \n",
    "    When Voldemort attempted to kill Harry, his curse rebounded and Harry survived with a lightning-shaped \n",
    "    scar on his forehead.\n",
    "  \"\"\"\n",
    "\n",
    "  #Tokenize input question and passage\n",
    "  #Special tokens : [CLS] and [SEP]\n",
    "\n",
    "  \"\"\"\n",
    "  [101, 2054, 4302, 9418, 102, 4302, 10693, 1998, 1996, 9667, 1005, 1055, 2962, 1010, 4302, \n",
    "  3268, 1999, 1037, 25337, 2104, 1996, 5108, 1999, 1996, 2160, 1997, 1996, 4241, 2869, 3051, \n",
    "  2015, 1010, 2010, 5916, 1010, 4470, 1998, 5542, 1010, 12648, 1012, 1996, 4241, 2869, 3051, \n",
    "  2015, 5136, 3209, 6669, 3671, 1010, 2021, 2012, 1996, 2287, 1997, 2340, 1010, 4302, 9418, \n",
    "  2008, 2002, 2003, 1037, 10276, 1012, 2002, 6010, 1037, 2431, 1011, 5016, 2315, 5292, 16523, \n",
    "  3593, 2040, 18675, 2032, 2000, 5463, 1996, 27589, 18367, 2015, 2082, 1997, 21599, 1998, 10276, \n",
    "  2854, 1012, 4302, 10229, 2008, 2004, 1037, 3336, 1010, 2010, 3008, 2020, 7129, 2011, 1996, \n",
    "  2601, 10276, 2935, 5285, 3207, 5302, 5339, 1012, 2043, 5285, 3207, 5302, 5339, 4692, 2000, 3102, \n",
    "  4302, 1010, 2010, 8364, 27755, 2098, 1998, 4302, 5175, 2007, 1037, 7407, 1011, 5044, 11228, \n",
    "  2006, 2010, 6130, 1012, 102]\n",
    "  \"\"\"\n",
    "\n",
    "  # 101 is ID of [CLS] token\n",
    "  # 102 os ID of [SEP] token\n",
    "  # Both indictes the starting and ending of the sentences\n",
    "  #  \n",
    "\n",
    "\n",
    "  input_ids = tokenizer_for_bert.encode(question, passage, max_length = max_len, truncation=True)\n",
    "  print(input_ids)\n",
    "\n",
    "  # calculating the length of question ad passage\n",
    "  sep_index = input_ids.index(102) \n",
    "  len_question = sep_index + 1 # length of question\n",
    "  len_passage = len(input_ids)-len_question # remaining will be length of passage\n",
    "\n",
    "\n",
    "  # seperate question and passage \n",
    "  segment_ids = [0]*len_question + [1]*(len_passage)\n",
    "  print(segment_ids)\n",
    "\n",
    "  \"\"\"\n",
    "  [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "  \"\"\"\n",
    "\n",
    "  # converts token_ids into tokens\n",
    "  tokens = tokenizer_for_bert.convert_ids_to_tokens(input_ids)\n",
    "  print(tokens)\n",
    "  \"\"\" \n",
    "  ['[CLS]', 'what', 'harry', 'discovers', '[SEP]', 'harry', 'potter', 'and', 'the', 'philosopher', \n",
    "    \"'\", 's', 'stone', ',', 'harry', 'lives', 'in', 'a', 'cupboard', 'under', 'the', 'stairs', \n",
    "    'in', 'the', 'house', 'of', 'the', 'du', '##rs', '##ley', '##s', ',', 'his', 'aunt', ',', \n",
    "    'uncle', 'and', 'cousin', ',', 'dudley', '.', 'the', 'du', '##rs', '##ley', '##s', 'consider', \n",
    "    'themselves', 'perfectly', 'normal', ',', 'but', 'at', 'the', 'age', 'of', '11', ',', 'harry', \n",
    "    'discovers', 'that', 'he', 'is', 'a', 'wizard', '.', 'he', 'meets', 'a', 'half', '-', 'giant', \n",
    "    'named', 'ha', '##gr', '##id', 'who', 'invites', 'him', 'to', 'attend', 'the', 'hog', '##wart', \n",
    "    '##s', 'school', 'of', 'witchcraft', 'and', 'wizard', '##ry', '.', 'harry', 'learns', 'that', 'as', \n",
    "    'a', 'baby', ',', 'his', 'parents', 'were', 'murdered', 'by', 'the', 'dark', 'wizard', 'lord', \n",
    "    'vol', '##de', '##mo', '##rt', '.', 'when', 'vol', '##de', '##mo', '##rt', 'attempted', 'to', \n",
    "    'kill', 'harry', ',', 'his', 'curse', 'rebound', '##ed', 'and', 'harry', 'survived', 'with', \n",
    "    'a', 'lightning', '-', 'shaped', 'scar', 'on', 'his', 'forehead', '.', '[SEP]']\n",
    "  \"\"\"\n",
    "  \n",
    "\n",
    "\n",
    "  # now here we have calculated the start and end token scores\n",
    "  # and converted into torch tensors\n",
    "\n",
    "  start_token_scores = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))[0]\n",
    "  end_token_scores = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))[1]\n",
    "  print(\"\\n\\nTorch Tensor Score of Start and End Tokens:\\n\",start_token_scores,\"\\n\",end_token_scores)\n",
    "\n",
    "  # converting the score tensors into numpy array\n",
    "  start_token_scores = start_token_scores.detach().numpy().flatten()\n",
    "  end_token_scores = end_token_scores.detach().numpy().flatten()\n",
    "  print(\"\\n\\nConverted Score of Tensor into Numpy Array:\\n\", start_token_scores,\"\\n\",end_token_scores)\n",
    "\n",
    "\n",
    "  # getting the start and end index of answer based on highest score\n",
    "  answer_start_index = np.argmax(start_token_scores) # function retuns the array of indices\n",
    "  answer_end_index = np.argmax(end_token_scores)\n",
    "  print(\"\\n\\nHighest Score that matches with index of answer:\\n\",answer_start_index,\"\\n\",answer_end_index)\n",
    "\n",
    "  # getting the max score of the start and end of the answer\n",
    "  start_token_scores = np.round(start_token_scores[answer_start_index], 2)\n",
    "  end_token_scores = np.round(end_token_scores[answer_end_index], 2)\n",
    "  print(\"\\n\\nMaximum Score of start and end of the answer:\\n\",start_token_scores,\"\\n\",end_token_scores)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # combining subwords between the start and end index of answer\n",
    "  answer = tokens[answer_start_index]\n",
    "  for i in range(answer_start_index + 1, answer_end_index + 1):\n",
    "    if tokens[i][0:2] == '##':\n",
    "      answer+=tokens[i][2:]\n",
    "    else:\n",
    "      answer+=' '+tokens[i]\n",
    "  \n",
    "\n",
    "  # if answer is not in the passage returns this message\n",
    "  if(answer_start_index == 0) or (start_token_scores < 0) or (answer == '[SEP') or (answer_end_index < answer_start_index):\n",
    "    answer = \"Sorry!, I could now find the answer in the passage.\"\n",
    "  \n",
    "  return (answer_start_index, answer_end_index, start_token_scores, end_token_scores, answer)\n",
    "\n",
    "\n",
    "bert_question_answer(\"What harry discovers\", \"Harry Potter and the Philosopher's Stone, Harry lives in a cupboard under the stairs in the house of the Dursleys, his aunt, uncle and cousin, Dudley. The Dursleys consider themselves perfectly normal, but at the age of 11, Harry discovers that he is a wizard. He meets a half-giant named Hagrid who invites him to attend the Hogwarts School of Witchcraft and Wizardry. Harry learns that as a baby, his parents were murdered by the dark wizard Lord Voldemort. When Voldemort attempted to kill Harry, his curse rebounded and Harry survived with a lightning-shaped scar on his forehead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the passage: 333 words\n",
      "\n",
      "Question 1:  The chamber was opened by whom\n",
      "\n",
      "Answer from BERT:  ginny weasley \n",
      "\n",
      "\n",
      "Question 2:  What ability harry discover in his second year at Hogwarts\n",
      "\n",
      "Answer from BERT:  harry discovers an ability to speak the snake language parseltongue \n",
      "\n",
      "\n",
      "Question 2:  Who was allegedly assisted in Harry's parents' murder\n",
      "\n",
      "Answer from BERT:  sirius black \n",
      "\n",
      "\n",
      "Question 4:  Harry and Hermione traveled back using what\n",
      "\n",
      "Answer from BERT:  time turner \n",
      "\n",
      "\n",
      "Question 5:  Harry reache which professor to learn patronus charm\n",
      "\n",
      "Answer from BERT:  remus lupin \n",
      "\n"
     ]
    }
   ],
   "source": [
    "passage = \"\"\" Potter and the Chamber of Secrets describes Harry's second year at Hogwarts. Students are attacked and petrified by an unknown creature; wizards of Muggle parentage are the primary targets. The attacks appear related to the Chamber of Secrets, a fifty-year-old mystery at the school. Harry discovers an ability to speak the snake language Parseltongue, which he learns is rare and associated with the Dark Arts. When Hermione is attacked, Harry and Ron uncover the chamber's secrets and enter it. Harry discovers that the chamber was opened by Ron's younger sister, Ginny Weasley, who was possessed by an old diary in her belongings. The memory of Tom Marvolo Riddle, Voldemort's younger self, resided inside the diary and unleashed the basilisk, an ancient monster that kills those who make direct eye contact. Harry draws the Sword of Gryffindor from the Sorting Hat, slays the basilisk and destroys the diary.\n",
    "In the third novel, Harry Potter and the Prisoner of Azkaban, Harry learns that he is targeted by Sirius Black, an escaped convict who allegedly assisted in his parents' murder. As Harry struggles with his reaction to the dementors – creatures guarding the school that feed on despair – he reaches out to Remus Lupin, a new professor who teaches him the Patronus charm. On a windy night, Ron is dragged by a black dog into the Shrieking Shack; Harry and Hermione follow. The dog is revealed to be Sirius Black. Lupin enters the shack and explains that Black was James Potter's best friend; he was framed by another friend of James', Peter Pettigrew, who hides as Ron's pet rat, Scabbers. As the full moon rises, Lupin transforms into a werewolf and bounds away; the group chase after him but are surrounded by dementors. They are saved by a mysterious figure who casts a stag Patronus. This is later revealed to be a future version of Harry, who traveled back in time with Hermione using the Time Turner. The duo help Sirius escape on a Hippogriff.\"\"\"\n",
    "\n",
    "print(f'Length of the passage: {len(passage.split())} words')\n",
    "\n",
    "question1 = \"The chamber was opened by whom\"\n",
    "print('\\nQuestion 1: ', question1)\n",
    "_, _, _, _, ans = bert_question_answer(question1, passage)\n",
    "print('\\nAnswer from BERT: ', ans, '\\n')\n",
    "\n",
    "\n",
    "question2 = \"What ability harry discover in his second year at Hogwarts\"\n",
    "print('\\nQuestion 2: ', question2)\n",
    "_, _, _, _, ans = bert_question_answer(question2, passage)\n",
    "print('\\nAnswer from BERT: ', ans, '\\n')\n",
    "\n",
    "\n",
    "question3 = \"Who was allegedly assisted in Harry's parents' murder\"\n",
    "print('\\nQuestion 2: ', question3)\n",
    "_, _, _, _, ans = bert_question_answer(question3, passage)\n",
    "print('\\nAnswer from BERT: ', ans, '\\n')\n",
    "\n",
    "\n",
    "question4 = \"Harry and Hermione traveled back using what\"\n",
    "print('\\nQuestion 4: ', question4)\n",
    "_, _, _, _, ans = bert_question_answer(question4, passage)\n",
    "print('\\nAnswer from BERT: ', ans, '\\n')\n",
    "\n",
    "question5 = \"Harry reache which professor to learn patronus charm\"\n",
    "print('\\nQuestion 5: ', question5)\n",
    "_, _, _, _, ans = bert_question_answer(question5, passage)\n",
    "print('\\nAnswer from BERT: ', ans, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the passage: 62 words\n",
      "\n",
      "Question 1:  What percentage of the Earth's surface is covered by the ocean?\n",
      "\n",
      "Answer from BERT:  70 % \n",
      "\n",
      "\n",
      "Question 2:  How does the ocean impact the planet's climate?\n",
      "\n",
      "Answer from BERT:  the ocean plays a crucial role in regulating \n",
      "\n"
     ]
    }
   ],
   "source": [
    "passage = \"\"\"The ocean is a vast and mysterious body of water that covers more than 70% of the Earth's surface. It is home to millions of species, some of which have yet to be discovered by humans. The ocean plays a crucial role in regulating the planet's climate and provides a source of food and livelihood for billions of people around the world.\"\"\"\n",
    "\n",
    "print(f'Length of the passage: {len(passage.split())} words')\n",
    "\n",
    "question1 = \"What percentage of the Earth's surface is covered by the ocean?\"\n",
    "print('\\nQuestion 1: ', question1)\n",
    "_, _, _, _, ans = bert_question_answer(question1, passage)\n",
    "print('\\nAnswer from BERT: ', ans, '\\n')\n",
    "\n",
    "\n",
    "question2 = \"How does the ocean impact the planet's climate?\"\n",
    "print('\\nQuestion 2: ', question2)\n",
    "_, _, _, _, ans = bert_question_answer(question2, passage)\n",
    "print('\\nAnswer from BERT: ', ans, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
